{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import urllib2 as ul\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import time\n",
    "import re\n",
    "import codecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def HanParse(pageno,write=0):\n",
    "    newspage = ul.urlopen('http://baduk.hangame.com/news.nhn?gseq='+str(pageno)+'&m=view&page=1&searchfield=&leagueseq=0&searchtext=')\n",
    "    soup = bs(newspage,'html.parser')\n",
    "    #[s.extract() for s in soup(['style', 'script', '[document]', 'head', 'title'])]\n",
    "    tmp = soup.getText()\n",
    "    tmp=u'내용'.join(tmp.split(u'내용')[2:])\n",
    "    b=tmp.find(u'관련 뉴스보기')\n",
    "    tmp=tmp[:b]\n",
    "    tmp='\\n'.join([i for i in tmp.split('\\n') if len(i)>0])\n",
    "    if write==1:\n",
    "        h=codecs.open('./han/'+str(pageno)+'.d','w',encoding='utf-8')\n",
    "        h.write(tmp)\n",
    "    return tmp\n",
    "\n",
    "def GetSent(pageno):\n",
    "    dat=HanParse(pageno)\n",
    "    sent = dat.split('.')[6:-1]\n",
    "    first = sent[0].split(u'내용')\n",
    "    sent[0]=first[-1]\n",
    "    return sent[:-3]\n",
    "\n",
    "def ReadSent(pageno,src='./han/'):\n",
    "    dat=codecs.open(src+str(pageno)+'.d',encoding='utf-8')\n",
    "    dat = dat.read()\n",
    "    dat = Clean(dat)\n",
    "    dat = dat.replace('?','.')\n",
    "    dat = dat.replace('!','.')\n",
    "    return [' '.join(i.split()) for i in dat.split('.')]\n",
    "    \n",
    "def Clean(sentence,comma=0):\n",
    "    if comma==0:\n",
    "        for i in ['\\n','_','-','(',')','\"','\\'',u'▲','...','[',']',u'■','<','>','\\r']:\n",
    "            sentence=sentence.replace(i,' ')\n",
    "    else:\n",
    "        for i in ['\\n','_','-','(',')','\"','\\'',u'▲','...','[',']',u'■','<','>',',','\\r']:\n",
    "            sentence=sentence.replace(i,' ')\n",
    "    return sentence.strip()\n",
    "\n",
    "def GetArticles(indexno):\n",
    "    articles=[]\n",
    "    main=ul.urlopen('http://baduk.hangame.com/news.nhn?&page='+str(indexno))\n",
    "    mainbs=bs(main,'html.parser')\n",
    "    tmp = [link.get('href') for link in mainbs.find_all('a')]\n",
    "    for j in tmp:\n",
    "        try:\n",
    "            if j.find('readnews')>0:\n",
    "                articles.append(j)\n",
    "        except AttributeError:\n",
    "            continue\n",
    "    mynews=[int(re.search(r'\\d+', i).group()) for i in articles]\n",
    "    mynews = sorted(list(set(mynews)))\n",
    "    return mynews\n",
    "\n",
    "def WordCount(pagelist,sort=1,sentence=0):\n",
    "    sentences=[]\n",
    "    words=[]\n",
    "    for page in pagelist:\n",
    "        \n",
    "        tmp=GetSent(page)\n",
    "        for sent in tmp:\n",
    "            sentences.append(Clean(sent))\n",
    "    for sent in sentences:\n",
    "        for j in sent.split():\n",
    "            words.append(j)\n",
    "    uwords = list(set(words))\n",
    "    wc = [(i,words.count(i)) for i in uwords]\n",
    "    if sort==1:\n",
    "        wc = sorted(wc, key=lambda x: x[1])\n",
    "        wc.reverse()\n",
    "    if sentence==0:\n",
    "        return wc\n",
    "    else:\n",
    "        return wc, sentence\n",
    "\n",
    "#a la https://github.com/mouuff/Google-Translate-API/blob/master/python/GoogleTranslate.py\n",
    "def translate(to_translate, to_langage=\"auto\", langage=\"auto\"):\n",
    "    to_translate=to_translate.encode('utf-8')\n",
    "    agents = {'User-Agent':\"Mozilla/4.0 (compatible; MSIE 6.0; Windows NT 5.1;SV1; .NET CLR 1.1.4322; .NET CLR 2.0.50727; .NET CLR 3.0.04506.30)\"}\n",
    "    before_trans = 'class=\"t0\">'\n",
    "    link = \"http://translate.google.com/m?hl=%s&sl=%s&q=%s\"% (to_langage, langage, to_translate.replace(\" \", \"+\"))\n",
    "    request = ul.Request(link, headers=agents)\n",
    "    page = ul.urlopen(request).read()\n",
    "    result = page[page.find(before_trans)+len(before_trans):]\n",
    "    result = result.split(\"<\")[0]\n",
    "    return result\n",
    "\n",
    "def MergeWords():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
