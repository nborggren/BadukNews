적은 힘으로 더 강한 알파고, TPU는 거들 뿐 (3편)
[바둑의 미래서밋] 
김수광  2017-08-13 오후 11:18   [프린트｜스크랩]
▲ 구글은 딥러닝을 위해 특화된 칩을 개발했다. TPU(Tensor Processing Unit)다. 사진은 2016년 3월 이세돌과 겨뤘던 알파고가 사용한 서버다. TPU가 장착돼 있다. 커제와의 대국 때는 2세대 TPU가 쓰였다. 서버 랙(rack) 한켠에 붙은 딥마인드 챌린지 매치 3국(이세돌  vs 알파고)의 기보가 인상 깊다.
알파고는 2016년 자태를 드러낸 지 2년도 안 되어 바둑계를 송두리째 바꿔 놓았다. 전 세계에 바둑이 무언지 모르는 사람이 없게 되었고, 더는 인간이 바둑을 가장 잘 두는 존재가 아니게 되었다. 인간은, 세계 최강의 실력을 갖춘 인공지능에게서 바둑의 진수를 배우고 있다. 한 시대를 지배하는 이론적 체계를 패러다임이라고 할 때 알파고가 바둑의 패러다임까지 바꾼 것은 아니지만 바둑이론의 상당부분을 수정하게끔 만들었다. 
알파고는 2017년 5월, 중국랭킹 1위이며 사실상 세계 일인자 커제를 3-0으로 제압한 뒤 은퇴했다. 선물도 남겼다. 알파고가 또 다른 알파고와 대국한 기보 50개가 공개됐다. 충격적이었다. 현재 인간의 이론으로는 도저히 해석할 수 없는 수준의 내용이었다. 최고 실력자들이 머리를 맞대고 연구하고 있는 한국국가대표팀상비군도 즉시 알파고의 바둑을 놓고 해부에 나섰지만 좀처럼 진척이 되지 않을 정도로 그 내용은 난해했다. 그들로서도 당장 해설을 해줄 수 없었다. 
그래서 기다렸다. 연구가 좀더 무르익을 때까지. 그리고 시간이 한참 흘러 국가대표상비군을 만나 바둑이론이 인공지능 알파고로 말미암아 얼마나 바뀌었는지, 이야기를 들어봤다. 시간이 지났다고 해도 국가대표팀이 알파고의 바둑을 훨씬 이해하게 된 것은 아니었다. 그래도 프로기사들이 체감하고 이해하는 폭이 처음과는 많이 달라져 있었다. 알파고의 모든 수를 속속들이 이해하지 못할지는 몰라도 지금까지 인간들이 어떤 고정관념에 갇혀 있었는지를 조금씩 알아가고 있었다. 
앞으로도 인간을 현격히 앞서가고 있는 알파고를 완벽히 이해하기란 쉽지 않은 일일 것이다. 그럼에도 연구는 멈추지 않을 것이다. 알파고의 바둑을 연구하는 것이 인간바둑 이론의 발전에 확실히 도움이 될 것이기에.
알파고가 두번째로 치른 공식대국인 바둑의 미래서밋을 취재한 얘기부터 현대바둑이론서들을 온통 물음표 투성이로 물들여 버린 알파고의 바둑수법 이야기까지 취재수첩 형식으로 다뤄 보고자 한다. 앞 부분은 취재 여정 중심으로, 뒤쪽에서는 알파고의 영향으로 눈에 띄게 바뀌어 버린 바둑이론 이야기로 꾸민다. 
  관련기사 ▶ (1편) 지도에도 없는 대국장소 (☞클릭!)  
  관련기사 ▶ (2편) 중국이 못 보는 중국 잔치 (☞클릭!)  
3편: 적은 힘으로 더 강한 알파고, TPU는 거들 뿐   
알파고의 버전이나 대회에 사용된 하드웨어 스펙을 구글은 알파고 vs 커제 1국이 끝난 뒤에야 알려줬다. 대회가 열리기 전에 적어도 버전 정도는 알려줄 줄 알았지만 구글은 하지 않았다.  
이런 사항은 대회 전에 공개해 줬으면 좋았겠다. 구글이 마케팅를 고려해 세운 나름의 전략인지 몰라도, 늦게 공개할수록 각종 루머만 양산할 뿐이다.  
▲ 미래의 바둑서밋 공개해설이 대회장 건물 내 무대에서 펼쳐지고 있다. 
이세돌과의 대국 때 알파고는 ‘버전18’이었다. 이번엔 숫자를 사용하지 않고 닉네임을 붙였다. 지난해 말부터 올 초 인터넷 세상에 나타나 60전 전승을 하고서 홀연히 사라졌던 아이디(ID) ‘마스터(Master)’를 그대로 사용한 ‘알파고 마스터 버전’이었다. 
그리고 TPU라는 걸 사용했다고 해서 매체들이 들썩였다. 매체 대부분이 “TPU(Tensor Processing Unit)를 이용했기에 알파고가 더 강력해졌다.”고 했다. 틀린 말은 아니지만 강조점은 구글의 설명과 달랐다.   
사람들은 컴퓨팅 파워(연산능력)에 눈길이 가게 돼 있나 보다. 연산력이 알파고가 바둑에서 사람을 이기게 하는 본질적인 힘인 것처럼 생각한다. 심지어 어떤 매체는 “구글이 TPU를 은근히 자랑하고 싶어서 미래의 바둑서밋에서 사용하는 알파고에 이런 하드웨어를 적용했으며, 전문 칩 제조사를 위협하기까지 한다.”는 내용으로 분석기사까지 내놓기도 했으니 놀라울 따름이다. 그런데 구글 딥마인드는 그렇지 않다고 말한다. 
구글 딥마인드 데이비드 실버(David Silver) 리서치 사이언티스트는 “컴퓨팅 파워가 아니라 알고리즘이 중요하다.”고 반복해서 말했다.  
▲ 커제(왼쪽)와 알파고의 바둑의 미래 서밋 2국이 끝난 순간. '바둑판 옆 모니터'는 이제 낯설지 않다. 
TPU는 코프로세서(Co-Processer)다. 코(Co)는 ‘돕는다’는 뜻으로 코프로세서는 CPU의 보조 역할을 한다. TPU는 행렬 연산의 병렬처리를 전담하며, CPU처럼 명령어 처리 등을 하지 않아 일반적인 프로그램을 돌릴 수는 없다. 하지만 딥러닝에 필요한 연산속도 하나는 기가 막히게 빠르다. 딥러닝을 위해서만 특화했다고 볼 수 있다.  
미래의 바둑서밋에서 알파고 마스터 버전에 사용된 하드웨어 스펙은 TPU(Tensor Processing Unit) 싱글머신(1대)이다. 그 안에 TPU 4개가 장착돼 있다. 이세돌과의 대국 때는 TPU 50개였으니 개수가 한참 줄었다. 그러나 이번에 사용한 건 ‘2세대’ TPU로서 학습과 연산이 동시에 가능하다. 신경망에 기반한 인공지능 관련 연산에서는 최신 CPU/GPU보다 15배~30배나 빠르다. 
그러나 어디까지나 ‘도우미’는 도우미다. 딥러닝을 하는 데 보다 전력 소모가 적고 보다 경량화하도록 TPU를 쓰는 것일 뿐 TPU가 알파고 실력의 본질이거나 비밀인 것은  아니다.  
구글 딥마인드는 “컴퓨팅 파워를 10분의 1로 줄였으나 알파고의 성능은 더 강화됐다.”고 했다. 막대한 컴퓨트 자원을 동원하지 않고도 놀라운 일을 해낼 수 있다는 뜻이다. 적은 힘으로 뛰어난 능력을 발휘한다면 범용성 증대에 유리하다. 저들이 목표로 삼는 게 범용성이다. 
그러니 알파고가 오직 TPU라는 칩 때문에 강해졌다고 설명하는 것은 강조점이 잘못돼 있다. 구글이 인텔이나 엔비디아(Nvidia)같은 CPU, GPU 칩 전문 제조사인 것도 아니고 TPU로 전문 제조사와 경쟁해보겠다는 심산은 없어 보인다. 그저 딥러닝에 전력 비용이 많이 들어가니 그것 좀 아끼고 범용성도 도모해 보자고 자체 개발했을 뿐이다. 
▲ TPU의 소비전력 당 수행성능의 뛰어남을 보여주는 표. 한마디로 '전기료 아끼는 데는 그만~'이런 거다. 
말이 나온 김에, 구글에 바람이 있다면 컴퓨팅 파워를 설명할 때 정확한 수치를 알려주면 좋겠다.  
지난해 3월 이세돌과 대국한 알파고의 컴퓨트 자원에 대해 구글은 “판후이 프로와 대국했던 때와 비슷한 수준”이라고 했다. 왜 ‘비슷한 수준’이라고 말하는지 모르겠다. ‘정확히 몇’이라 말하면 되는 것을.  
그래서 당시 우리나라의 많은 언론 매체들은 별수 없이 판후이와 겨뤘던 때의 수치를 보도했다. 즉 ‘CPU 1202개 + GPU 176개’라고 썼다. 그런데 또 다른 ‘설’이 돌았다. ‘CPU 1920개 + GPU 280개’라고 보도한 매체도 있었던 것. 이렇게 두 개 버전이 존재했다. 
이로부터 두달이 흐른 2016년 5월, 구글 I/O개발자회의에선 ‘TPU 50개를 사용했다’고 밝혔다. 전혀 다른 얘기다! 
그러더니 2017년 미래의 바둑서밋 대회 기간 열렸던 인공지능의 미래 포럼에서 데이비드 실버 박사는 온갖 세세한 얘기는 빼고 “지난해엔 “TPU 50개를 썼지만 이번 마스터 버전에선 TPU 싱글머신을 썼으며 그 안엔 TPU 4개를 장착했다.”고 했다. 
▲ 미래의 바둑서밋 프레스 컨퍼런스에서 대국자와 개발자의 목소리에 귀를 기울이고 있는 기자들. 기자들은 정확한 정보를 전하기 위해 귀를 연다. 
나는 머리를 감싸쥐며 현장에서 구글 코리아에 문의했다(현장에서 구글 코리아 사람을 만나기는 수월하지 않았다). 답변은 다음과 같았다. 
“작년엔 CPU 2000개 수준, TPU 50개 수준이었고 이번엔 CPU 200개 수준에 TPU 싱글머신이다.”
왜 이렇게 이렇게 매번 얘기가 다르냐고 물었더니 “저희도 전달받은 만큼 내용을 전달할 수 있을 뿐 정확히 알 수 없다.”는 답이 돌아왔다. 
‘도대체 어떻게 된 걸까. 아, 그래. 어떤 의미인지는 대략 짐작이 간다. 1202나 1920이나 저들의 시각에서는 큰 차이가 없는 것이겠지. 큰 대회에 사용하는 것 치고는 별로 많이 사용하지 않았다는 점에선 같다고 말하고 싶은 거겠지. 1202나 1920나 2000 미만인 것은 매한가지고, GPU 역시 어느 것이든 수십~수백 개 수준이라는 뜻이겠지…. 그런데 이세돌 vs 알파고 대국 때, 왜 TPU 얘기는 아예 나오지도 않은 거지? 아~ 그때는 TPU 개발 초기이고 1세대라 TPU의 역할이 아주 크진 않아 유달리 언급하지 않은 거겠지…' 
그래 다 좋다. 이렇게 유추해 나가면 된다. 그런데 내가 왜 스무고개를 하고 있는지 모르겠다. 구글이 한마디로 딱 정리해 주면 좋지 않나? 구글 외에는 아무도 모르는 것들이다. 
혹시 구글 딥마인드 CEO 데미스 하사비스(Demis Hassabis) 박사도 다른 강연에서 알파고에 사용된 컴퓨팅 파워 수준을 표현하며 “사용한 GPU는 수백 개 수준”이라고 했다. IT 문외한들을 걱정해서 쉽게 표현하려고 그랬는지 모른다. 좋은 뜻에서 그러는 것 잘 알겠다. 그래도 그냥 정확한 수치를 말해주면 좋겠다. 그게 모두에게 유익하다. 안 그러면 서로 헷갈린다. (4편에서 계속)
 
 [사진 | 구글]
 
 
 
 