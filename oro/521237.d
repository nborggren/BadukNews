학습하는 인공지능, 이세돌에게 도전장 
[이세돌 VS 알파고] 
김수광   2016-01-29 오전 01:34   [프린트｜스크랩]	      
 
▲ 구글 딥마인드 개발팀(왼쪽이 데이비스 하사미스 구글 딥마인드 CEO, 오른쪽이 데이비스 실버 리서치 사이언티스트 ), 그리고 질의응답하는 한국 기자들. 각각 런던과 한국에서 화상으로 대화했다. 

          인공지능이 프로기사를 이기는 충격적인 사건이 벌어졌다. 
접바둑이 아니라 호선(even)이다. 
구글(Google) 딥마인드(Deep Mind) 사업부가 만든 인공지능 ‘알파고’가 비공개대국에서 프로기사 판후위 2단과 다섯 대국을 펼쳤는데 모두 이겼다. 
어찌된 일일까. 
현존 대부분의 인공지능 바둑이 몬테카를로 방식을 채용한다. 가장 뛰어난 것은 프로기사에게 넉점 접바둑으로 버티는 수준까지 도달했다. 하지만 앞으로 프로기사와 맞서려면 적어도 10년 이상의 기술 진보가 있어야 한다는 게 일반적 예상 아니었나. 
비결은 ‘학습(Learning)’이었다. 
인공지능 바둑은 2000년대 ‘몬테카를로 트리서치’ 도입을 거치면서 비약적으로 발전했다. 그러나 최근에 와선 몬테카를로 트리서치만으로는 한계가 있다고 여겨지고 있었다. 무작위착수로 모의대국을 수없이 해보고(한마디로 아무데나 막 두는 것이다) 그 승률을 따져 착수 후보마다 점수를 매겨 다음 착수를 결정하는 이 방식은 컴퓨터의 탐색 시간을 단축시키고 승리 확률을 높였지만 획기적인 실력 상승이 나타나지 않고 있었다. 몬테카를로는 ‘무작위’와 ‘모의실험 결과’에 의존한다. 그 말의 연원처럼 너무 ‘도박적’이었다. 전 세계 개발자들 사이에선 패러다임의 변화가 필요하다는 말이 돌았다. 
그러던 차에, 비밀리에 인공지능 바둑을 개발하던 구글이 판도를 확 바꿔놨다. 
구글 딥마인드는 몬테카를로 트리서치에 기계학습(Machine Learning)을 결합시켰다. 
학습은 인간의 고유 영역이었지만 이제는 기계도 학습을 한다. IBM, 페이스북, 구글 같은 세계의 손꼽는 기업들이 기계학습에 분야에서 경쟁을 가속화하고 있다. 구글의 번역기, 무인 자동차, 페이스북의 얼굴 인식 기능 등이 모두 인공지능, 그리고 기계학습으로 이뤄지는 것이다. 
지난해 11월20일 구글 딥마인드의 CEO이자 엔지니어 데미스 하사비스 (Demis Hassabis)는 유투브 영상으로 인공지능이 바둑으로 사람을 이길 수 있는 방도를 찾았다는 듯한 이야기를 한 뒤 “바둑과 관련해 몇 달안에 상당히 놀랄만한 일이 일어날 것”이라고 런던왕립학회(Royal Society of London)와 인터뷰했다. 구글은 비밀리에 인공지능 바둑을 개발하고 있었기에 공개적 회견이 아니었고, 슬쩍 ‘흘렸다’고 할 수 있었다. 
기자는 그때 그저 시원하게 웃었다. 천하의 구글이라지만 바둑을 잘 모르고 오만방자하구나’라고까지 생각했다. 구글의 비밀프로젝트가 실체가 있는 것이라 믿었고, 세계적인 인재들이 모였으니 뭔가 더 잘할 수 있을 거라고 생각은 했다. 그렇다고는 하나, 이렇다 할 결과를 내기까지 몇 년은 더 걸릴 것이라고 생각했으니, 구글이 허풍에 가까운 호언장담을 하는 것이라고 볼 수밖에 없었다. 
그러나 2016년 1월28일 구글이 그간의 일들을 발표하고 나올 때 기자는 ‘멘붕’에 빠졌다. 판후이 2단이 프랑스에서 활동하고 있긴 하지만 중국프로기사다. 입단은 아무나 하는 게 아니다. 고스톱 잘한다고 프로되는 게 아니다. 프로인 그가 인공지능에게 진 사실이 밝혀졌다. 
▲ 판후이 2단과 대국하는 동안 인공지능 알파고 내부에선 이런 작업이 벌어진다. [네이처] 
사이버오로 [집중조명]으로 프로바둑을 분석&해설해 오고 있는 바람의검심 오로7단★은 인공지능 ‘알파고’와 판후이 2단의 다섯 대국을 보고 난뒤 “알파고는 잘 정돈된 바둑이다. 단단하게 두다가 상대가 허술한 틈을 보이면 응징한다. 훌륭하다. 실로 놀랍다.” 고 했다. 
최철한 9단은 “판후이 2단이 판판이 초반에 망했다. 그러는 바람에 알파고가 난전에 강한지 아직 파악이 어렵다”고 말했다. 
구글은 12억원(100만달러)을 걸고 이세돌 9단과 알파고의 대결을 성사시켰다. 다섯판을 두며, 더 많이 이긴 사람이 우승한다. 3월에 서울에서 열린다. 
최철한 9단은 “2점 치수로 보인다. 알파고의 약점을 파악하지 못하는 한 석점 접기는 어려워 보인다.”며 이세돌 9단이 어렵지 않게 승리할 것으로 봤다. 
  ●○ '인간 대표' 이세돌, 구글 AI와 '100만 달러' 놓고 대결  ☞ 보기 클릭   
  ●○ 커제도 놀랐다 ‘어느 쪽이 인공지능이야?’☞ 보기 클릭   
 ■	구글 딥마인드의 프레스 브리핑  
구글은 자신들은 성과를 28일 서울 강남구의 구글코리아에서 발표했다. 한국의 언론매체 100여명이 참석했다. 발표할 사람은 단상에 보이지 않고 대형모니터만 두 개 있었다. 구글의 메신저 애플리케이션 ‘행아웃(Hangout)’으로 런던 딥마인드 본사 내부가 비춰졌다. 그 영상 속에 사흘 동안 잠을 자지 못해 퀭해진 눈의 딥마인드의 CED 데미스 하사미스와 데이비스 실버(리서치 사이언티스트)가 나타났다. 그리고 네이처지 관계들도 나와 있었는데 내내 아무말 없이 앉아 있었다. 
화상으로 브리핑과 질의응답이 이뤄졌다.  
딥마인드는 2014년 1월 구글이 4억달러에 인수한 인공지능(AI, Artificial Inteligence) 분야 기업이다. 영국 런던에 본사를 둔 딥마인드는 업계 최고의 엔지니어, 과학자, 연구원들을 보유하고 있다. 이들은 머신러닝과 시스템 신경과학(system neuroscience) 분야의 기술을 활용해 강력한 범용 학습 알고리즘을 구축하고 있다. 
CEO 데미스 하사미스가 “바둑은 인간이 만들어낸 가장 복잡한 게임이다. 바둑의 수는 우주의 원소 수보다 많다. 바둑은 인공지능 연구자들을 좌절시키는 거대한 난제였다. 한국에서 많은 이들이 평생을 바쳐 바둑을 연구하고 있다고 들었다.”고 했다. 
그러면서 “기존 인공지능은 평범한 아마추어 실력 수준에 머물렀다. 이번에 인공지능 알파고가 프로기사(판후이)를 꺾은 것은 인공지능 분야에서 획기적인 일이다. 이세돌 9단이 도전을 받아준 데 대해 기쁘게 생각한다.’라고 했다. 
※ 인공지능 알파고의 특징 
모든 가능한 위치에 탐색 트리(search tree)를 구성하는 전통적 방식의 인공지능은 바둑에서만큼은 빛을 발하지 못했다. 그래서 딥마인드는 다른 접근방식을 취했다. '알파고(AlphaGo)'라는 시스템을 구축했는데, 이는 고급 트리 탐색과 심층 신경망(deep neural networks)을 결합한 것이다.  
이 신경망은 수백만 개의 신경세포와 같은 연결고리를 포함하는 12개의 프로세스 레이어를 통해 바둑판을 분석한다. '정책망(policy networks)'이라고 부르는 하나의 신경망이 다음 번 돌을 놓을 위치를 선택한다. '가치망(value networks)'이라고 부르는 또다른 신경망은 승자를 예측한다.  
▲ 알파고가 다음 착수를 분석하는 방식 [네이처]
한편 데이비스 실버(리서치 사이언티스트)는 기술적인 부분을 브리핑했다. 그는 “우리는 바둑의 복잡함·방대함을 단순화해서 그 영역을 축소시켰다. 그러자면 트리서치와 함께 심층신경망이 필요했다. 여기엔 다층적 신경세포와 같은 연결고리를 활용했다.”고 말했다. 
※ 심층신경망 (Deep Neural Network) 
딥러닝의 한 기법이다. 딥러닝은 높은 수준의 추상화를 시도하는 기계학습(Machine learning) 알고리즘의 집합이다. 인공신경망에 기반해 설계됐다. 과학자들은 기계가 스스로 학습하도록 하기 위해 사람의 사고방식을 취하도록 인간 두뇌를 흉내내는 인공 신경망을 고안해냈다. 컴퓨터가 특정 과업을 수행할 때 스스로 필요한 데이터를 수집하고 분석하며 고속으로 처리할 수 있다. 컴퓨팅 성능이 높아진 배경에서 주목받는다.  
그는 어떻게 바둑의 복잡함을 해결 가능하게 했는지 이렇게 얘기했다. “가치망(Value networks)이 탐색할 트리의 길이를 줄였다(컴퓨터의 탐색 부담을 줄여준다). 정책망(Policy networks)은 고수들의 기보(records)로 3천만개의 움직임에 대해 알파고를 훈련시켰다. 이로써 사람이 다음에 어떻게 둘지를 더 잘 예측하게 됐다. 과거 44%에서 57%까지 증가했다.”고 했다. 또 “신경망을 사용해 가상으로 바둑을 두게 하고, 강화학습을 바탕으로 시행착오 프로세스를 사용하여 연결망을 조절하면서 스스로 전략을 발견하면서 학습하게 했다. 이는 기존에 불가능했던 걸 가능하게 했다. 다른 인공지능 바둑프로그램들과 겨뤄  499승 1패했다. 개중엔 몇 점 치수가 나는 프로그램도 있었다.”
 ■	구글 딥마인드의 질의응답 
 질문) 바둑전용알고리즘으로 어떻게 현실의 문제를 해결할 수 있나? 
→ 기본적으로 (인공지능이) 바둑에서 이기기 위해선 몇 가지의 기능과 역량을 가져야 한다. 형상(바둑판)을 인지해야 하고, 강화학습을 바탕으로 지속적으로 대국하고 몬테카를로 트리서치로 검색을 해야 한다. 현실세계에서도 체계와 구조를 찾아내면 장기적인 계획을 세울 수 있다. 
알파고는 바둑만이 아니라 다른 분야에도 적용할 수 있는 범용 알고리즘이다. 예전에 아타리(Atari)라는 게임사가 만든 게임을 대상으로 적용해 봤더니 인공지능이 게임을 어떻게 하면 잘할지를 학습하면서 찾아내고 있음을 확인할 수 있었다. 즉, 우리는 '바둑전용' 알고리즘 같은 걸 사용하지 않았고 범용알고리즘을 사용한다는 것이다. 
예컨대 유럽 여행을 계획한다고 하자 스마트폰으로 숙박 예약을 하려면 인공지능 알고리즘이 여러분의 선호도를 이해해야 한다. 기존에 사용한 방법을 학습하여 휴가 때 무엇을 좋아하는지, 그러니까 박물관을 좋아하는지 콘서트를 좋아하는지 따위를 패턴 인식해 여행을 알차게 활용하고 정해진 시간을 가장 유익하게 보내도록 짜 준다.  
또 의료 진단을 예로 들어 보자. CT스캔이나 MRI영상정보 처리에서 인공지능이 몸에 이상한 점을 발견하고서 적절한 진단계획을 수립할 수 있다.  
 질문) 아이비엠과 구글의 인공지능을 비교해 봐 달라. 그리고 빅데이터가 없으면, 즉 적은 데이터로는 러닝이 불가능한가? 또 알파고가 이세돌 9단의 패턴을 다 학습한 상태에서 대국하나 아니면 전혀 모른채 대국에 임하나?   
→ 1997년 딥블루가 체스 챔피언 가리 카스파로프를 꺾은 것, 또 왓슨(Watson) 컴퓨터가 2011년 '제퍼디(Jeopardy)'에서 우승한 것 등이 아이비엠 인공지능의 성과다. 97년 얘기를 하자면 딥블루는 대입검색방식으로 20~30수씩을 내다보면서 일일이 모든 경우의 수를 예측했다. 거기엔 역대 체스 고수들의 기술 데이터가 들어가 있는 엑스퍼트 시스템을 사용했다. 
무작위 대입은 경우의 수를 찾아내는 것이지만 중요한 것은 ‘얼마만큼’ 하느냐는 것이다. 거기에 우리와의 차이가 있다. 바둑은 검색량이 너무 많다. 제퍼디 퀴즈의 경우도, 당시 특별한 사례를 데이터베이스화해서 입력해 놓고 질문이 나오면 특정 주제를 검색하게 했다. 
그에 반해 알파고는 범용시스템이다. 좀 더 단순한, 계층화된 프로세스를 사용한다. 입력된 정보를 불러오는 게 아니라. 기본적인 데이터를 사용은 하지만 학습하면서 다음 수를 예측한다. 그게 차이다.
덧붙이자면 데이터가 있어야 하긴 하지만 학습을 통해서 비로소 진보한다. 인간에 비해 학습 효율은 떨어진다. 신경과학 얘기들을 하곤 하시는데, 인간의 경우는 ‘하나를 들으면 열을 안다’고 할까’. 기계는 그렇지 못하다. 
빅데이터에 대한 질문을 하셨는데, 머신러닝은 효과가 있으려면 어느 정도 데이터가 필요하다. 전문가의 기보를 공부하고 게임하는 과정에서 학습이 이뤄진다. 그렇지만 이런 게 없이도 강화학습을 통해 자가학습을 하고 실력을 높일 수는 있다.  
또 이세돌 9단의 패턴에 관해 말하자면, 특정기사의 패턴을 바탕으로 하지 않았다. 
 질문) 알파고도 실수를 하나?  
“몬테카를로가 무작위접근법이라서 확률적으로 실수 가능성은 내재한다. 하지만 신경망이 철저히 분석하기에 실수 확률은 줄어든다.”
 질문) 형세를 판단하려면 실리, 세력 그리고 국면 모두를 읽어야 한다. 이런 걸 어떻게 통합시켰나(얼마나 다양한 evaluation function을 사용했나, 목적함수를 win probablity로 지정했다, 다른 방법도 있을 텐데 왜 win probablity로 했나)?  
→ 하나의 평가시스템을 쓴다. 트레이드 오프로 계산한다. 어느 특정 관점이 아닌, 인간이 중요하게 생각하는 것이 아닌 어떻게 하면 이길 수 있는가를 고민하게 했다. 알파고는 처음에 인간이 어떻게 형세의 균형을 찾는지 내용을 학습하면서 출발하고 2단계에서는 튜닝을 한다. 이렇듯 자가 경기를 통해 균형을 찾아가는 것이다. 이세돌 9단이 대국을 치른 뒤 이에 대해 어떤 소감을 말해줄지 궁금하다. 바둑으로 아마추어인 우리가 만들어낸 시스템을 세계최고의 기사가 어떻게 평가할 것인지 말이다.  
 질문) 여타 인공지능이 대중적으로 몬테카를로 트리서치를 사용한다.  
→ 몬테카를로 트리서치가 승률 면에서 성공적이었던 건 탐색과 결과를 통해 승리를 따지기 때문이다. 과거 이런 시스템이 개발됐을 때는 전제된 목적은 ‘이기는 것’이었다. 알파고는 게임의 ‘끝’이 아니라 대국 도중 한 수 한 수를 평가하는 데 중점을 둔다.” 
 질문) 알파고의 훈련 기간은 며칠이었나? 
→  4주 동안 중단없이 100만번의 경기를 진행했다. 보통 기사가 1년에 1000번의 대국을 한다고 가정할 때 알파고는 인간 세상 1000년치 경험을 쌓은 셈이다.  
 질문) 이세돌 9단에게 지면 재도전할 텐가?  
→ 만약 지면 재도전을 고민하겠다. 이긴다면 경기분석을 하고 선수 등록도 고려는 해볼 수 있겠다. 하지만 지금은 다가올 대국의 준비에 신경 쓰고 있다. 
 질문) 누가 이길 것으로 예상하나? 
→ 50 대 50으로 본다. 이세돌 9단도 자신있다고 말했지만 우리도 자신있다. 
 
 
 
 