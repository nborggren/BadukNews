단신
다시 인간과 대국하는 알파고
23일 커제 vs 알파고 1국 시작
2017-05-23 오전 8:51:10 입력
             / 2017-05-23 오전 10:29:19 수정
 
바둑의 미래서밋 중국프로기사 랭킹1위이며 세계 최강이라 일컫는 커제 9단은 인공지능과 3번기(23일ㆍ25일ㆍ27일)를 벌인다. 장소는 중국 '우전 인터넷 국제 컨벤션센터 (Wuzhen Internet International Conference and Exhibition Center, 乌镇互联网国际会展中心)'. 커제는 세계대회에서 네 차례 우승했으며 현재 삼성화재배 월드바둑마스터스와 몽백합배 세계바둑오픈 타이틀을 보유 중이다. 우승상금은 150만 달러(약 17억원). 상금과 별도로 커제는 출전료 30만 달러(약 3억 4000만원)를 확보했다(이세돌은 딥마인드 매치 당시 15만달러를 받았다). 제한시간은 3시간 60초 5회(이세돌과의 매치 때는 2시간 60초 3회.)26일에는 단체전(상담기:논의하며 여럿이 힘을 합쳐 두는 바둑)과 페어전이 벌어진다. 단체전에는 스웨(时越), 천야오예(陈耀烨), 미위팅(芈昱廷), 탕웨이싱(唐韦星), 저우루이양(周睿羊)이 출전하여 알파고와 겨루고, 페어전은 ‘구리 알파고’ vs ‘롄샤오 알파고’ 의 대결로 펼쳐진다. 단체전 제한시간은 각 2시간 30분 초읽기 60초3회. 페어전은 각 1시간, 초읽기 1분 1회. 타이젬은 5월23일부터 27일까지 열리는 '바둑의 미래 서밋' 에서 벌어지는 대국들을 유명 프로기사의 해설로 타이젬대국실에서 생중계할 예정이다. 바둑의 미래 서밋 - 타이젬 해설 23일(화) 알파고 vs 커제 1국: 김승재 7단 25일(목) 알파고 vs 커제 2국: 소소회 9단 26일(금) 알파고 vs 5인(스웨·천야오예·미위팅·탕웨이싱·저우루이양): 허영호 9단 27일(토) 알파고 vs 커제 3국: 김정현 6단
▲ 대회장 앞 거리. 작은 규모의 호텔과 식당이 즐비하다. ‘직관과 창의’ 아직도 탐구 중 우리는 알파고와 구면이다. 알파고와 인간의 대국이 또다시 이뤄지는 이유는 무엇일까 인공지능 알파고는 지난 10년간 바둑계를 주름잡았던 이세돌 9단을 격파했다. 또 온라인서버에서 세계 최정상기사들을 상대로 60전 전승을 거뒀다. 승부로는 이룰 만큼 이뤘다. 그런 알파고가 계속해서 인간과 대국을 벌인다. 바둑계로서는 반가운 일이지만 제작사 구글 딥마인드의 생각은 뭘까. 한쪽에서는 이런 추측이 나온다. “구글(딥마인드)이 인공지능업계에서 자신들이 최고임을 과시하고 브랜드 이미지를 제고하려는 것이다…” 그러나 구글은 이미 인공지능의 아이콘으로 등극했다. 차라리 ‘최고봉으로서 경쟁사들의 추격에 쐐기를 박으려는 것이다. 또 한 번 바둑으로 인간을 압도해 상징적인 승리를 과시하려는 것:이라고 해석하는 게 좀 더 어울릴지 모른다. 구글과 바둑과 인공지능으로 치열한 자존심 싸움을 벌였던 페이스북(Facebook)은 경쟁에서 저만치 뒤처졌다. 다크포레스트(DarkForest) 프로젝트가 알파고 프로젝트에 무릎을 꿇었다. 그러나 이것이 하나의 대답은 될 수 있겠지만 충분하지는 않은 것 같다. 구글이 다시 알파고로 인간과 대결을 벌이는 이유를 알기 위해선 딥마인드가 과연 무엇을 목적으로 삼는 회사인지를 되새겨볼 필요가 있다. 딥마인드는 범용적 목적을 지니는 학습 시스템을 만들고자 한다. 그게 딥마인드의 창설 배경이다. 저들은 우선 지능을 풀어내고(solve intelligence) 그러고 나선 외부세계에 적용하여 인류를 위해 쓰겠다고 한다. 이것이 딥마인드의 직접적인 대답이다. 직관의 정체는 무엇인가? ‘그것을 아는 데 도달했나?’ 하는 의문은 여전하다. 구글 딥마인드 CEO 데미스 하사비스(Demis Hassabis) 박사는 “직관이란 경험을 통해 획득되는, 내재된 지식(Implicit knowledge)이라 정의하면서 “직관은 의식수준에서 표현이 가능하고, 소통 가능하다.”고 말한다. 다시 말해 직관이란 게 마냥 무의식 속에 머물러 있는 것이 아니며 경험을 많이 하다 보면 길러질 수 있다는 것이다. 그리고 그것이 무엇인지 우리가 쉽게 표현할 수 있고 그걸 주제로 대화도 나눌 수 있다는 이야기다. 데미스 하사비스는 이세돌 9단과 알파고가 벌였던 딥마인드챌린지매치 제4국에서 이세돌의 78수에 알파고가 혼란을 일으킨 것을 아직도 인상 깊게 기억한다. 올 1월 독일에서 열린 DLD컨퍼런스에서 강연자로 나선 데미스 박사는 그 4국에 있었던 것과 같은 지식의 간극(Knowledge gap)을 개선(fix)하고 최적화하는 데 우리는 아직도 박차를 가하고 있다.”고 말했다. 바둑은 계산으로만 끝나는 게 아니기에 어떤 이들은 ‘인간이 기계의 연산 능력을 쫓아갈 수 없으므로 이미 바둑에서 인간과 기계의 승부는 종언을 고했고 더 이상 의미 없다.’고 본다. 재미있는 사실은 정작 딥마인드는 그렇게 보지 않고 있다는 것이다. 데미스 박사는 “체스라면 그렇다. 체스는 계산으로 이뤄지는 게임이며 어떤 수를 두었을 때 왜 여기 두었다고 명확한(explicit) 대답을 할 수 있지만 바둑은 직관과 본능에 의존하기에 바둑 고수들은 거기에 둬야 할 것 같은 느낌이었다고 대답한다'고 말한다.사람의 뇌는 현실세계에 존재하는 범용적 학습 시스템이다. 따라서 인공지능을 연구하는 이들은 생물학적 뇌를 관찰하고 뇌인지과학에서 힌트를 얻는다. 게임(아타리 게임 같은)은 현실세계에 대한 소우주이다. 그중에서도 바둑은 직관과 창의를 규명할 수 있는 도구다. 데미스 박사는 “창의성이란 지식을 합성할 수 있는 능력이다. 그것은 기발하고 독창적인 아이디어로 어떤 목적을 위한 생산을 가능하게 한다.”고 말한다. 그는 중국바둑일인자 커제 9단의 바둑의 진리를 향한 탐구열에서 자연을 연구하는 과학자들의 태도와 동질성이 있음을 느낀다. 프로기사(바둑인)이나 과학자나 진리를 탐구하는 자세에선 매한가지라는 것이다. 알파고는 과학과 게임과, 고전과 정신이 교차하는 지점에 서 있다. 데미스 박사는 “우리는 바둑계에 알파고를 보낸다. 알파고는 분명히 바둑이론 발전에 도움을 줄 것이다. 천체과학자들은 허블 망원경으로 우주를 본다. 바둑 전문가들은 알파고를 통해 바둑의 진리를 볼 것”이라고 말한다. 중국랭킹 1위이면서 어쩌면 세계랭킹 1위일 수 있는 커제 9단과 알파고가 ‘바둑의 미래서밋(summit)’에서 만난다. 23일부터 그 맞대결이 시작된다. 어떤 알파고가 나올까 2016년 3월 이세돌과 대결했던 알파고는 버전18이었다. 2016년 12월31일~2017년 1월4일까지 온라인서버에 나타나 인간고수를 60대0으로 이긴 알파고는 ‘새 버전’이었다고 딥마인드 측은 밝혔다. 이번 커제와 맞붙는 알파고의 버전은 미공개상태다. 인간의 기보를 전혀 거치지 않은 버전 이른바 ‘버전 2.0’이 나온다는 예측도 나오지만 아직 확인되지 않은 상태다. 그렇게 된다면 정말 상상초월하는 바둑의 양상이 될 수도 있다. 그렇지 않더라도 또 다른 새 버전이기에 이번 알파고는 지금까지와 다른 모습을 보일 것이서 더욱 호기심을 자극한다. 
 
 
알파고 학습원리 복습 직관의 국면을 포착하기 위해 알파고는 ‘지도학습’과 ‘강화학습’의 강점을 결합했다. 과거 인간이 두어온 기보 빅데이터에서 포지션을 추출해 반상을 확률분포로 만들고 정책망(policy network)이라는 인공신경망을 훈련시켰다. 그 뒤엔 자가 경기(self play)로 강화학습이라는 시행착오 프로세스를 사용해 연결고리를 조정해 스스로 새로운 전략을 발견하는 법을 학습했다. 이를 바탕으로 두번째 신경망을 만들었다. 가치망(value network)이다. 누가 이기고 있으며 또 얼마나 이기고 있는지를 예측하는 형세판단 체계다. ‘가치망’은 셀프 대국에서 특정 위치에 놓인 돌을 보고 승리 확률을 예측하여 -1(상대편의 승리 확실)부터 1(알파고의 승리 확실)까지의 점수를 매긴다. 정책망과 가치망은 자체적으로도 강력한 힘을 가지고 있지만, 알파고는 ‘몬테카를로 트리 탐색’ 기술로 이 두 가지를 결합하여 더욱 강력한 힘을 발휘하고 있다. 이 탐색 기법은 정책망을 통해 분기계수를 줄이는 한편 가치망을 통해 정확한 조기 종료를 가능케 함으로써 엄청난 효율성 증대를 가져온다. 이렇게 하여 새로운 버전으로 업그레이드된 알파고는 지속적으로 셀프대국을 하고 이를 다음 세대를 위한 훈련 데이터로 활용한다. 이런 반복이 알파고의 학습이다. 
 대국 시 알파고의 내부에선~ 상대방이 바둑판에 돌을 놓으면 알파고는 몬테카를로 트리 탐색을 수행하여 최적의 수를 결정한다. 각 시뮬레이션은 게임 트리에서 하나의 경로를 지나게 되는데, 여기서 정책망에 따라 Q값(해당 수의 가치를 예측한 값)이 높으면서 개연성도 높은 수들을 선택한다. 시뮬레이션은 가치망 예측치와 롤아웃으로 종료되는데, 롤아웃은 정책에 기반하여 매우 빠른 속도로 계산을 수행한다. 알파고는 시뮬레이션에서 각 수의 Q값을 가치망 예측치와 롤아웃 결과의 평균값으로 업데이트한다. 할당된 탐색 시간이 지나면 알파고는 탐색 횟수가 가장 많은 수를 최적의 수로 판단하고, (이 수의 가치망 예측치가 가장 높지 않더라도) 이에 맞추어 플레이한다. 즉 알파고의 탐색 알고리즘은 먼저 광범위한 탐색 과정을 거친 뒤 시간이 지남에 따라 최적의 수를 다듬어 결정하는 것이다.